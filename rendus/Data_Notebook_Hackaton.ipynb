{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üèì Hackathon Ynov 2025 ‚Äî Mega Notebook Data (FINAL)\n",
        "\n",
        "Notebook **complet** pour le bar√®me Data, align√© sur **ton script SQL**.\n",
        "- **Sans** d√©pendance √† `DOCUMENTATION_BDD.pdf`\n",
        "- Compatible **CSV** *ou* **PostgreSQL** (toggle `USE_PG`)\n",
        "- Inclut : Cleaning, Structuring, EDA, **Elo**, **Pr√©diction gagnant (am√©lior√©e)**, exports & plots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Imports & configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, re, math, json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'figure.dpi': 120})\n",
        "\n",
        "# D√©tection Colab vs local\n",
        "BASE = Path('/content') if Path('/content').exists() else Path('.')\n",
        "RENDU = BASE/'rendus'; RENDU.mkdir(exist_ok=True)\n",
        "PLOTS = BASE/'plots'; PLOTS.mkdir(exist_ok=True)\n",
        "\n",
        "# Candidats CSV (ajoute /content et /mnt/data)\n",
        "CSV_CANDIDATES = [\n",
        "    BASE/'babyfoot_dataset.csv',\n",
        "    BASE/'data'/'babyfoot_dataset.csv',\n",
        "    Path('/mnt/data/babyfoot_dataset.csv'),\n",
        "    Path('babyfoot_dataset.csv'),\n",
        "]\n",
        "SCHEMA_PATH = BASE/'db_schema.sql' if (BASE/'db_schema.sql').exists() else Path('/mnt/data/db_schema.sql')\n",
        "CSV_PATH = next((p for p in CSV_CANDIDATES if p and p.exists()), None)\n",
        "print('üìÇ BASE =', BASE.as_posix())\n",
        "print('‚úÖ CSV =', CSV_PATH if CSV_PATH else '‚ùå non trouv√©')\n",
        "print('‚úÖ SQL =', SCHEMA_PATH if (SCHEMA_PATH and SCHEMA_PATH.exists()) else '‚ùå non trouv√©')\n",
        "try:\n",
        "    # Lister pour debug\n",
        "    import subprocess, sys\n",
        "    if BASE.as_posix() == '/content':\n",
        "        subprocess.run(['bash','-lc','ls -lh /content || true'])\n",
        "    subprocess.run(['bash','-lc','ls -lh /mnt/data || true'])\n",
        "except Exception:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Connexion aux donn√©es (choisir une source)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Option A ‚Äî CSV\n",
        "if CSV_PATH:\n",
        "    for enc in ['utf-8','latin-1','cp1252']:\n",
        "        try:\n",
        "            df_raw = pd.read_csv(CSV_PATH, encoding=enc, low_memory=False)\n",
        "            used_enc = enc\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "    print('Lecture CSV OK ‚Äî encoding =', used_enc)\n",
        "else:\n",
        "    df_raw = None\n",
        "    print('CSV non trouv√© ‚Äî passez √† USE_PG=True si vous avez une BDD.')\n",
        "\n",
        "# Option B ‚Äî PostgreSQL (d√©sactiv√©e par d√©faut)\n",
        "USE_PG = False  # ‚¨ÖÔ∏è Passe √† True si tu veux lire depuis ta BDD\n",
        "if USE_PG:\n",
        "    import sqlalchemy as sa\n",
        "    PG_URL = os.getenv('PG_URL', 'postgresql+psycopg2://user:pass@localhost:5432/foos')\n",
        "    eng = sa.create_engine(PG_URL)\n",
        "    games = pd.read_sql('select * from games', eng)\n",
        "    players = pd.read_sql('select * from players', eng)\n",
        "    game_players = pd.read_sql('select * from game_players', eng)\n",
        "    tables_foos = pd.read_sql('select * from tables_foos', eng)\n",
        "    telemetry = pd.read_sql('select * from telemetry', eng)\n",
        "    # tables paris (option bonus)\n",
        "    bettors = pd.read_sql('select * from bettors', eng)\n",
        "    bet_types = pd.read_sql('select * from bet_types', eng)\n",
        "    bets = pd.read_sql('select * from bets', eng)\n",
        "    bet_selections = pd.read_sql('select * from bet_selections', eng)\n",
        "    print('Tables charg√©es depuis PostgreSQL')\n",
        "else:\n",
        "    games=players=game_players=tables_foos=telemetry=bettors=bet_types=bets=bet_selections=None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Helpers de standardisation (√©quipes, dur√©es, scores)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def to_int(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    if isinstance(x, (int, np.integer)): return int(x)\n",
        "    if isinstance(x, float) and float(x).is_integer(): return int(x)\n",
        "    s=str(x); m=re.search(r'-?\\d+', s.replace(',', '.'))\n",
        "    return int(m.group(0)) if m else np.nan\n",
        "\n",
        "def to_float(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    if isinstance(x,(int,float,np.integer,np.floating)): return float(x)\n",
        "    s=str(x).strip().replace(',', '.')\n",
        "    try: return float(s)\n",
        "    except:\n",
        "        m=re.search(r'-?\\d+(\\.\\d+)?', s)\n",
        "        return float(m.group(0)) if m else np.nan\n",
        "\n",
        "def parse_duration_to_seconds(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    s=str(x).strip().lower().replace(',', '.')\n",
        "    if re.match(r'^\\d{1,2}:\\d{2}:\\d{2}$', s):\n",
        "        h,m,sec=map(int,s.split(':')); return h*3600+m*60+sec\n",
        "    if re.match(r'^\\d{1,2}:\\d{2}$', s):\n",
        "        m,sec=map(int,s.split(':')); return m*60+sec\n",
        "    h=m=sec=0\n",
        "    m1=re.search(r'(\\d+)\\s*h',s); m2=re.search(r'(\\d+)\\s*m',s); m3=re.search(r'(\\d+)\\s*s',s)\n",
        "    if m1 or m2 or m3:\n",
        "        if m1: h=int(m1.group(1))\n",
        "        if m2: m=int(m2.group(1))\n",
        "        if m3: sec=int(m3.group(1))\n",
        "        return h*3600+m*60+sec\n",
        "    if 'min' in s:\n",
        "        val=to_float(s); return int(round(val*60)) if val==val else np.nan\n",
        "    if s.endswith('s'):\n",
        "        val=to_float(s[:-1]); return int(round(val)) if val==val else np.nan\n",
        "    val=to_float(s); return int(round(val*60)) if val==val else np.nan\n",
        "\n",
        "TEAM_MAP={'red':'Red','r':'Red','rouge':'Red','rd':'Red','blue':'Blue','b':'Blue','bleu':'Blue','bl':'Blue'}\n",
        "def norm_team(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    s=str(x).strip().lower(); return TEAM_MAP.get(s, s.capitalize())\n",
        "\n",
        "def norm_winner(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    s=str(x).strip().lower()\n",
        "    if 'red' in s or 'rouge' in s or s=='r': return 'Red'\n",
        "    if 'blue' in s or 'bleu' in s or s=='b': return 'Blue'\n",
        "    return s.capitalize()\n",
        "\n",
        "def parse_score_cell(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    s=str(x).strip().lower().replace(',', '.')\n",
        "    m=re.match(r'^\\s*(\\d+)\\s*[-:x]\\s*(\\d+)\\s*$', s)\n",
        "    if m: return float(m.group(1))\n",
        "    val=to_float(s); return float(val) if val==val else np.nan\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Chargement/normalisation (CSV ou jointure BDD)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if df_raw is not None:\n",
        "    df = df_raw.copy()\n",
        "    df['game_dt'] = pd.to_datetime(df.get('game_date', df.get('game_datetime')), errors='coerce')\n",
        "    df['table_id_std'] = df.get('table_id','').astype(str).str.upper().str.strip()\n",
        "    df['team_std'] = df.get('team_color', df.get('team')).apply(norm_team)\n",
        "    df['score_red_num']  = df.get('final_score_red', df.get('score_red')).apply(parse_score_cell)\n",
        "    df['score_blue_num'] = df.get('final_score_blue', df.get('score_blue')).apply(parse_score_cell)\n",
        "    df['winner_std'] = df.get('winner').apply(norm_winner)\n",
        "    df['duration_s'] = df.get('game_duration', df.get('duration_s')).apply(parse_duration_to_seconds)\n",
        "    df['player'] = np.where(\n",
        "        df.get('player_canonical_name').notna() & (df.get('player_canonical_name').astype(str).str.strip()!=''),\n",
        "        df.get('player_canonical_name').astype(str).str.strip(),\n",
        "        df.get('player_name', df.get('name')).astype(str).str.strip()\n",
        "    )\n",
        "    role_map={'attack':'Attack','att':'Attack','atk':'Attack','defense':'Defense','def':'Defense','gk':'Defense'}\n",
        "    if 'player_role' in df.columns:\n",
        "        df['player_role_std'] = df['player_role'].astype(str).str.lower().map(role_map).fillna(df['player_role'])\n",
        "    else:\n",
        "        df['player_role_std'] = np.nan\n",
        "    for c_in, c_out in [('player_goals','goals'),('player_saves','saves')]:\n",
        "        if c_in in df.columns:\n",
        "            df[c_out] = df[c_in].apply(to_int).fillna(0).astype(int)\n",
        "        else:\n",
        "            df[c_out] = 0\n",
        "else:\n",
        "    if all(t is not None for t in [games, game_players, players]):\n",
        "        df = (game_players\n",
        "              .merge(games, on='game_id', how='left', suffixes=('','_g'))\n",
        "              .merge(players[['player_id','name','age']], on='player_id', how='left'))\n",
        "        df.rename(columns={'name':'player','team':'team_std','player_role':'player_role_std','game_datetime':'game_dt'}, inplace=True)\n",
        "        df['score_red_num'] = df['score_red']\n",
        "        df['score_blue_num'] = df['score_blue']\n",
        "        df['winner_std'] = df['winner']\n",
        "        df['duration_s'] = df['duration_s']\n",
        "        df['goals'] = df['goals'].fillna(0).astype(int)\n",
        "        df['saves'] = 0\n",
        "    else:\n",
        "        raise RuntimeError('Aucune source de donn√©es trouv√©e. Fournissez CSV ou activez USE_PG.')\n",
        "\n",
        "# Nettoyages de base\n",
        "df['duration_s'] = df['duration_s'].clip(lower=0)\n",
        "df['goals'] = df['goals'].clip(lower=0).fillna(0).astype(int)\n",
        "df['saves'] = df['saves'].clip(lower=0).fillna(0).astype(int)\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) D√©-doublonnage & reconstruction scores/vainqueur par match"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "dup_keys=[c for c in ['game_id','player_id','team_std'] if c in df.columns]\n",
        "dups=df.duplicated(subset=dup_keys, keep='first') if dup_keys else pd.Series(False, index=df.index)\n",
        "df_nodup=df.loc[~dups].copy(); print('Duplications retir√©es :', int(dups.sum()))\n",
        "\n",
        "g_players=df_nodup.groupby(['game_id','team_std'], as_index=False).agg(goals=('goals','sum'))\n",
        "pvt=g_players.pivot(index='game_id', columns='team_std', values=['goals']).fillna(0)\n",
        "pvt.columns=[f\"{a}_{b}\" for a,b in pvt.columns]\n",
        "for col in ['goals_Blue','goals_Red']:\n",
        "    if col not in pvt.columns: pvt[col]=0\n",
        "pvt=pvt.reset_index(); pvt['score_red_from_players']=pvt['goals_Red']; pvt['score_blue_from_players']=pvt['goals_Blue']\n",
        "\n",
        "if {'score_red_num','score_blue_num'}.issubset(df_nodup.columns):\n",
        "    g_decl=df_nodup.groupby('game_id', as_index=False).agg(\n",
        "        score_red_decl=('score_red_num','max'),\n",
        "        score_blue_decl=('score_blue_num','max'),\n",
        "        winner_decl=('winner_std', lambda s: s.dropna().mode().iat[0] if len(s.dropna()) else np.nan),\n",
        "        game_dt=('game_dt','max'),\n",
        "        table_id=('table_id_std','max')\n",
        "    )\n",
        "else:\n",
        "    g_decl=df_nodup.groupby('game_id', as_index=False).agg(\n",
        "        score_red_decl=('score_red','max'),\n",
        "        score_blue_decl=('score_blue','max'),\n",
        "        winner_decl=('winner','max'),\n",
        "        game_dt=('game_dt','max'),\n",
        "        table_id=('table_id','max')\n",
        "    )\n",
        "\n",
        "g=pd.merge(g_decl, pvt[['game_id','score_red_from_players','score_blue_from_players']], on='game_id', how='left')\n",
        "\n",
        "def choose_score(row, side):\n",
        "    decl=row[f'score_{side}_decl']; from_pl=row[f'score_{side}_from_players']\n",
        "    if pd.isna(decl) and not pd.isna(from_pl): return int(from_pl)\n",
        "    if not pd.isna(decl) and not pd.isna(from_pl):\n",
        "        if abs(float(decl)-float(from_pl))>=2: return int(from_pl)\n",
        "        return int(round(float(decl)))\n",
        "    if not pd.isna(decl): return int(round(float(decl)))\n",
        "    if not pd.isna(from_pl): return int(from_pl)\n",
        "    return np.nan\n",
        "\n",
        "g['score_red']=g.apply(lambda r: choose_score(r,'red'), axis=1)\n",
        "g['score_blue']=g.apply(lambda r: choose_score(r,'blue'), axis=1)\n",
        "\n",
        "def decide_winner(row):\n",
        "    if pd.notna(row['winner_decl']) and row['winner_decl'] in ('Red','Blue'): return row['winner_decl']\n",
        "    sr,sb=row['score_red'],row['score_blue']\n",
        "    if pd.notna(sr) and pd.notna(sb):\n",
        "        if sr>sb: return 'Red'\n",
        "        if sb>sr: return 'Blue'\n",
        "    return np.nan\n",
        "\n",
        "g['winner']=g.apply(decide_winner, axis=1)\n",
        "g.head(2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) EDA & bar√®me ‚Äî Top buteurs / D√©fenseurs / Impact camp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Top 10 buteurs\n",
        "top_scorers=(df_nodup.groupby('player', as_index=False)\n",
        "             .agg(goals=('goals','sum'), matches=('game_id','nunique'))\n",
        "             .sort_values(['goals','matches'], ascending=[False, True])\n",
        "             .head(10))\n",
        "display(top_scorers)\n",
        "\n",
        "# Top 5 d√©fenseurs\n",
        "if 'saves' in df_nodup.columns and (df_nodup['saves'].sum()>0):\n",
        "    top_defenders=(df_nodup.groupby('player', as_index=False)\n",
        "                   .agg(saves=('saves','sum'), matches=('game_id','nunique'))\n",
        "                   .sort_values(['saves','matches'], ascending=[False, True])\n",
        "                   .head(5))\n",
        "else:\n",
        "    team_scores=g[['game_id','score_red','score_blue']]\n",
        "    df_def=df_nodup[df_nodup['player_role_std'].astype(str).str.lower().str.contains('def')]\n",
        "    def_agg=df_def.groupby(['game_id','team_std'])['player'].apply(list).reset_index()\n",
        "    def_agg=def_agg.merge(team_scores, on='game_id', how='left')\n",
        "    def conceded(row): return row['score_blue'] if row['team_std']=='Red' else row['score_red']\n",
        "    def_agg['conceded']=def_agg.apply(conceded, axis=1)\n",
        "    rows=[]\n",
        "    for _,r in def_agg.iterrows():\n",
        "        for p in r['player']:\n",
        "            rows.append({'player':p,'conceded':r['conceded']})\n",
        "    td=pd.DataFrame(rows)\n",
        "    top_defenders=(td.groupby('player', as_index=False)\n",
        "                     .agg(defensive_impact=('conceded','mean'), matches=('player','count'))\n",
        "                     .sort_values(['defensive_impact','matches'], ascending=[True, False])\n",
        "                     .head(5))\n",
        "\n",
        "display(top_defenders)\n",
        "\n",
        "# Impact camp (test proportion vs 50%)\n",
        "games_w=g.dropna(subset=['winner']).copy()\n",
        "red_wins=int((games_w['winner']=='Red').sum()); blue_wins=int((games_w['winner']=='Blue').sum())\n",
        "n=red_wins+blue_wins\n",
        "p_hat=red_wins/n if n>0 else float('nan')\n",
        "z=(p_hat-0.5)/math.sqrt(0.25/n) if n>0 else float('nan')\n",
        "from math import erfc, sqrt\n",
        "p_value=erfc(abs(z)/sqrt(2)) if n>0 else float('nan')\n",
        "print({'matches_with_winner':n,'red_wins':red_wins,'blue_wins':blue_wins,'red_win_rate':round(p_hat,4),'p_value_vs_50pct':round(p_value,4)})\n",
        "\n",
        "# Exports bar√®me\n",
        "top_scorers.to_csv(RENDU/'top10_buteurs.csv', index=False)\n",
        "top_defenders.to_csv(RENDU/'top5_defenseurs.csv', index=False)\n",
        "print('Exports ‚Üí top10_buteurs.csv & top5_defenseurs.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Visualisations (Grafana-like) + Playbook SQL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "win_counts=g['winner'].value_counts(dropna=True)\n",
        "plt.figure(figsize=(6,4)); plt.bar(win_counts.index.astype(str), win_counts.values)\n",
        "plt.title('Victoires par camp'); plt.xlabel('Camp'); plt.ylabel('Victoires'); plt.tight_layout(); plt.savefig(PLOTS/'wins_by_team.png'); plt.show()\n",
        "\n",
        "top_tables=g.groupby('table_id').size().sort_values(ascending=False).head(10)\n",
        "plt.figure(figsize=(8,4)); plt.bar(top_tables.index.astype(str), top_tables.values)\n",
        "plt.title('Top 10 tables les plus utilis√©es'); plt.xlabel('Table'); plt.ylabel('Matchs'); plt.xticks(rotation=45); plt.tight_layout(); plt.savefig(PLOTS/'top_tables.png'); plt.show()\n",
        "\n",
        "g['hour']=pd.to_datetime(g['game_dt']).dt.hour\n",
        "hour_counts=g.dropna(subset=['hour']).groupby('hour').size().reindex(range(24), fill_value=0)\n",
        "plt.figure(figsize=(8,4)); plt.plot(hour_counts.index.astype(int), hour_counts.values, marker='o')\n",
        "plt.title('Heures de pointe ‚Äî matchs par heure'); plt.xlabel('Heure'); plt.ylabel('Matchs'); plt.tight_layout(); plt.savefig(PLOTS/'peak_hours.png'); plt.show()\n",
        "\n",
        "playbook = f\"\"\"\n",
        "# Playbook SQL (align√© au sch√©ma)\n",
        "\n",
        "## 1) Victoires par camp\n",
        "SELECT winner, COUNT(*) AS wins FROM games WHERE winner IN ('Red','Blue') GROUP BY winner;\n",
        "\n",
        "## 2) Top 10 tables les plus utilis√©es\n",
        "SELECT table_id, COUNT(*) AS matches FROM games GROUP BY table_id ORDER BY matches DESC LIMIT 10;\n",
        "\n",
        "## 3) Heures de pointe\n",
        "SELECT EXTRACT(HOUR FROM game_datetime) AS hour, COUNT(*) AS matches FROM games GROUP BY hour ORDER BY hour;\n",
        "\n",
        "## 4) Top buteurs\n",
        "SELECT p.name, SUM(gp.goals) AS goals FROM game_players gp JOIN players p USING(player_id)\n",
        "GROUP BY p.name ORDER BY goals DESC LIMIT 10;\n",
        "\n",
        "## 5) Top d√©fenseurs (fallback Defensive Impact si pas de saves)\n",
        "-- Calculez les buts conc√©d√©s par l'√©quipe lorsque le joueur est en Defense, puis moyenne par joueur.\n",
        "\"\"\"\n",
        "(RENDU/'Playbook_Data.md').write_text(playbook, encoding='utf-8')\n",
        "print('√âcrit ‚Üí', (RENDU/'Playbook_Data.md').as_posix())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) BONUS ‚Äî Elo joueurs (mode √©quipe)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from collections import defaultdict, deque\n",
        "K=24; ELO0=1000.0\n",
        "order=g.dropna(subset=['game_dt']).sort_values('game_dt')['game_id'].tolist()\n",
        "gp=df_nodup[['game_id','player','team_std']].dropna()\n",
        "elo=defaultdict(lambda:ELO0)\n",
        "for gid in order:\n",
        "    row=g.loc[g['game_id']==gid].iloc[0]\n",
        "    tr=gp[(gp.game_id==gid)&(gp.team_std=='Red')]['player'].tolist()\n",
        "    tb=gp[(gp.game_id==gid)&(gp.team_std=='Blue')]['player'].tolist()\n",
        "    if not tr or not tb or pd.isna(row['winner']): continue\n",
        "    elo_r=np.mean([elo[p] for p in tr]); elo_b=np.mean([elo[p] for p in tb])\n",
        "    exp_r=1/(1+10**((elo_b-elo_r)/400)); score_r=1.0 if row['winner']=='Red' else 0.0\n",
        "    delta=K*(score_r-exp_r)\n",
        "    for p in tr: elo[p]+=delta\n",
        "    for p in tb: elo[p]-=delta\n",
        "elo_df=pd.DataFrame({'player':list(elo.keys()),'elo':[round(v,1) for v in elo.values()]})\n",
        "elo_df=elo_df.sort_values('elo', ascending=False).head(20)\n",
        "display(elo_df)\n",
        "elo_df.to_csv(RENDU/'leaderboard_elo.csv', index=False)\n",
        "\n",
        "plt.figure(figsize=(8,5)); plt.barh(elo_df['player'].astype(str)[::-1], elo_df['elo'].values[::-1])\n",
        "plt.title('Leaderboard Elo (Top 20)'); plt.xlabel('Elo'); plt.ylabel('Joueur'); plt.tight_layout(); plt.savefig(PLOTS/'leaderboard_elo.png'); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) üîÆ BONUS ‚Äî Pr√©diction du gagnant (am√©lior√©e)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import sin, cos, pi\n",
        "from collections import defaultdict, deque\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "if len(g) < 50:\n",
        "    print('‚ö†Ô∏è Pas assez de matchs pour entra√Æner un mod√®le fiable.')\n",
        "else:\n",
        "    # 1) Features enrichies sans fuite\n",
        "    K=24; ELO0=1000.0\n",
        "    elo = defaultdict(lambda: ELO0)\n",
        "    hist = defaultdict(lambda: deque(maxlen=5))\n",
        "    table_stats = defaultdict(lambda: {'red':0,'blue':0})\n",
        "\n",
        "    rows = []\n",
        "    g_ord = g.dropna(subset=['game_dt']).sort_values('game_dt').reset_index(drop=True)\n",
        "    gp = df_nodup[['game_id','player','team_std']].dropna()\n",
        "\n",
        "    for _, row in g_ord.iterrows():\n",
        "        gid = row['game_id']\n",
        "        team_r = gp[(gp.game_id==gid)&(gp.team_std=='Red')]['player'].tolist()\n",
        "        team_b = gp[(gp.game_id==gid)&(gp.team_std=='Blue')]['player'].tolist()\n",
        "        if not team_r or not team_b: continue\n",
        "\n",
        "        elo_r = np.mean([elo[p] for p in team_r])\n",
        "        elo_b = np.mean([elo[p] for p in team_b])\n",
        "        diff_elo = elo_r - elo_b\n",
        "\n",
        "        key_r=('R',tuple(sorted(team_r))); key_b=('B',tuple(sorted(team_b)))\n",
        "        form_r=np.mean(hist[key_r]) if len(hist[key_r]) else 0.0\n",
        "        form_b=np.mean(hist[key_b]) if len(hist[key_b]) else 0.0\n",
        "        diff_form=form_r-form_b\n",
        "\n",
        "        wr_r=np.mean([1 if x>0 else 0 for x in hist[key_r]]) if len(hist[key_r]) else 0.0\n",
        "        wr_b=np.mean([1 if x>0 else 0 for x in hist[key_b]]) if len(hist[key_b]) else 0.0\n",
        "        diff_wr=wr_r-wr_b\n",
        "\n",
        "        t=str(row['table_id'])\n",
        "        reds=table_stats[t]['red']; blues=table_stats[t]['blue']\n",
        "        bias=(reds/(reds+blues) if reds+blues>0 else 0.5)-0.5\n",
        "\n",
        "        hour=pd.to_datetime(row['game_dt']).hour if pd.notna(row['game_dt']) else 12\n",
        "        hour_sin, hour_cos = sin(2*pi*hour/24.0), cos(2*pi*hour/24.0)\n",
        "\n",
        "        y = 1 if row['winner']=='Red' else (0 if row['winner']=='Blue' else np.nan)\n",
        "\n",
        "        rows.append({\n",
        "            'y': y,\n",
        "            'diff_elo': diff_elo,\n",
        "            'diff_form': diff_form,\n",
        "            'diff_wr': diff_wr,\n",
        "            'table_bias': bias,\n",
        "            'hour_sin': hour_sin,\n",
        "            'hour_cos': hour_cos\n",
        "        })\n",
        "\n",
        "        # update apr√®s match\n",
        "        if pd.notna(row['score_red']) and pd.notna(row['score_blue']):\n",
        "            diff=row['score_red']-row['score_blue']\n",
        "            hist[key_r].append(diff)\n",
        "            hist[key_b].append(-diff)\n",
        "        if pd.notna(row['winner']):\n",
        "            exp_r=1/(1+10**((elo_b-elo_r)/400))\n",
        "            delta=K*((1 if row['winner']=='Red' else 0)-exp_r)\n",
        "            for p in team_r: elo[p]+=delta\n",
        "            for p in team_b: elo[p]-=delta\n",
        "        if row['winner']=='Red': table_stats[t]['red']+=1\n",
        "        elif row['winner']=='Blue': table_stats[t]['blue']+=1\n",
        "\n",
        "    feats=pd.DataFrame(rows).dropna(subset=['y'])\n",
        "\n",
        "    # 2) Entra√Ænement + calibration + seuil\n",
        "    X=feats[['diff_elo','diff_form','diff_wr','table_bias','hour_sin','hour_cos']].values\n",
        "    y=feats['y'].values\n",
        "    Xtr,Xte,ytr,yte=train_test_split(X,y,test_size=0.25,random_state=42,stratify=y)\n",
        "\n",
        "    base=GradientBoostingClassifier(n_estimators=400, max_depth=3, learning_rate=0.03)\n",
        "    clf=CalibratedClassifierCV(base, cv=5, method='sigmoid')\n",
        "    clf.fit(Xtr,ytr)\n",
        "\n",
        "    probs=clf.predict_proba(Xte)[:,1]\n",
        "    best_thr,best_acc=0.5,-1\n",
        "    for thr in np.linspace(0.35,0.65,31):\n",
        "        acc=accuracy_score(yte,(probs>=thr))\n",
        "        if acc>best_acc: best_acc,best_thr=acc,thr\n",
        "\n",
        "    print({'accuracy':round(best_acc,3),'roc_auc':round(roc_auc_score(yte,probs),3),'best_threshold':round(best_thr,3),'n_test':len(yte)})\n",
        "\n",
        "    y_pred=(probs>=best_thr).astype(int)\n",
        "    pd.DataFrame({'y_true':yte,'y_pred':y_pred,'y_prob':probs}).to_csv(RENDU/'prediction_winner_results.csv', index=False)\n",
        "    print('‚úÖ Nouveau CSV :', (RENDU/'prediction_winner_results.csv').as_posix())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) (Optionnel) Paris ‚Äî KPIs (si tables pr√©sentes via PG)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if bets is not None and bet_types is not None and bettors is not None:\n",
        "    b=bets.merge(bet_types, on='bet_type_id', how='left').merge(bettors, on='bettor_id', how='left')\n",
        "    b['implied_prob']=b['odds_den']/(b['odds_num']+b['odds_den'])\n",
        "    b['stake_eur']=b['stake_cents']/100.0; b['payout_eur']=b['payout_cents']/100.0\n",
        "    kpis=b.groupby('description', as_index=False).agg(\n",
        "        bets=('bet_id','count'), stakes=('stake_eur','sum'), payouts=('payout_eur','sum'), avg_implied_prob=('implied_prob','mean')\n",
        "    ).sort_values('bets', ascending=False)\n",
        "    display(kpis)\n",
        "    kpis.to_csv(RENDU/'betting_kpis_by_type.csv', index=False)\n",
        "else:\n",
        "    print('Tables de paris non disponibles ‚Äî section saut√©e.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) Validation de sch√©ma (checks rapides)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "schema_text = SCHEMA_PATH.read_text(encoding='utf-8') if SCHEMA_PATH and SCHEMA_PATH.exists() else ''\n",
        "must_have=['players','tables_foos','games','game_players','telemetry','bettors','bet_types','bets','bet_selections']\n",
        "missing=[t for t in must_have if f'CREATE TABLE {t}' not in schema_text]\n",
        "print('Tables manquantes (si vide: OK) ‚Üí', missing)\n",
        "if '\"condition\"' not in schema_text:\n",
        "    print('‚ö†Ô∏è Rappel: tables_foos.\"condition\" doit √™tre entre guillemets dans SQL.')\n",
        "if 'LANGUAGE plpgsq' in schema_text and 'LANGUAGE plpgsql' not in schema_text:\n",
        "    print('‚ö†Ô∏è Probable typo: utilisez LANGUAGE plpgsql pour la fonction settle_moneyline_bets.')\n",
        "else:\n",
        "    print('Fonction de r√®glement: langage OK ou non d√©tect√©.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11) Exports finaux & check-list bar√®me"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "g_sel=g[['game_id','score_red','score_blue','winner','game_dt']].rename(columns={'game_dt':'game_datetime'})\n",
        "df_out=df_nodup.merge(g_sel, on='game_id', how='left')\n",
        "df_out.to_csv(RENDU/'dataset_final.csv', index=False)\n",
        "\n",
        "checklist = {\n",
        "  'Data Cleaning': {'Standardisation': True, 'Nettoyage': True, 'Duplications': True, 'Anomalies': True},\n",
        "  'Structuring': {'Sch√©ma BDD coh√©rent (script)': True, 'Visualisations (plots + playbook)': True},\n",
        "  'Analyses': {'Top10 buteurs': True, 'Top5 d√©fenseurs (fallback ok)': True, 'Impact camp': True},\n",
        "  'Bonus': {'Elo': True, 'Pr√©diction ML (am√©lior√©e)': True}\n",
        "}\n",
        "Path(RENDU/'checklist.json').write_text(json.dumps(checklist, indent=2, ensure_ascii=False), encoding='utf-8')\n",
        "print('Exports OK ‚Üí', (RENDU/'dataset_final.csv').as_posix(), 'et', (RENDU/'checklist.json').as_posix())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}